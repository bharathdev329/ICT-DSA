# -*- coding: utf-8 -*-
"""Loan prediction intermediate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19SyJYwVvFXQ9Vwn1e7CHF3DcipDp3TLh
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

d=pd.read_csv('/content/train_ctrUa4K (1).csv')
train=pd.DataFrame(d)
train

train.info()

train.isna().sum()
#

#Dropping irrelevent columns

train.drop(['Loan_ID'],axis=1,inplace=True)

#Handelling Missing values

train['Credit_History'].fillna(0,inplace=True)
train['Self_Employed'].fillna('No',inplace=True)
train["Dependents"].fillna('NA',inplace=True)
train["Gender"].fillna('Other',inplace=True)
train["Married"].fillna('Yes',inplace=True)

train['LoanAmount'].fillna(train['LoanAmount'].median(),inplace=True)
train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].median(),inplace=True)

train['Total_Income']=train['ApplicantIncome']+train['CoapplicantIncome']
train.drop(['ApplicantIncome','CoapplicantIncome'],axis=1,inplace=True)

train.isna().sum()

train.info()



from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

for col in train.columns:
  if train[col].dtype=='object':
    train[col]=le.fit_transform(train[col])

train

outlier_col=[]
for column in train.select_dtypes(include=['float64']):
    q1 = train[column].quantile(0.25)
    q3 = train[column].quantile(0.75)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    outliers = train[(train[column] < lower_bound) | (train[column] > upper_bound)][column]
    print(f"Number of outliers in {column}: {len(outliers)}")
    count=outliers.shape[0]

    if count>0:
        outlier_col.append(column)
print(outlier_col)

import scipy.stats as stats
z=np.abs(stats.zscore(train[outlier_col]))
data_clean=train[(z<3).all(axis=1)]
print(data_clean.shape)

sns.countplot(data_clean['Loan_Status'])
data_clean['Loan_Status'].value_counts()

from sklearn.utils import resample
import numpy as np
import pandas as pd
train_majority = data_clean[data_clean['Loan_Status']==1]
train_minority = data_clean[data_clean['Loan_Status']==0]
train_minority_upsampled = resample(train_minority,
                                    replace=True,
                                    n_samples=len(train_majority),
                                    random_state=0)
train_upsampled = pd.concat([train_majority,train_minority_upsampled])
train_upsampled['Loan_Status'].value_counts()

x = train_upsampled.drop('Loan_Status',axis=1)
y = train_upsampled['Loan_Status']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

from sklearn.tree import DecisionTreeClassifier
d_tree = DecisionTreeClassifier(random_state=0)
d_tree.fit(x_train,y_train)

from sklearn.metrics import accuracy_score

y_pred = d_tree.predict(x_test)
print('Accuracy Score', round(accuracy_score(y_test, y_pred)*100,2), '%')

from sklearn.metrics import accuracy_score, f1_score , precision_score, recall_score
print('f-1 score',(f1_score(y_test, y_pred)))
print('precision score :', (precision_score(y_test, y_pred)))
print('recall score :', (recall_score(y_test, y_pred)))

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(random_state = 0)
rf.fit(x_train,y_train)

y_pred = rf.predict(x_test)
print('Accuracy Score', round(accuracy_score(y_test, y_pred)*100,2), '%')

test = pd.read_csv('/content/test_lAUu6dG (1).csv')

test_model = rf.predict(train.drop(columns=['Loan_Status'])) # Drop the column 'Loan_Status' from the 'train' dataframe.

test_model

test.isna().sum()

test_drop = test.drop('Loan_ID', axis=1)

test['Gender'].fillna('other',inplace=True)
test['Married'].fillna('No',inplace=True)
test['Dependents'].fillna('other',inplace=True)
test['Self_Employed'].fillna('No',inplace=True)
test['LoanAmount'].fillna(0,inplace=True)
test['Loan_Amount_Term'].fillna(0,inplace=True)
test['Credit_History'].fillna(0,inplace=True)

test.isna().sum()

test = pd.get_dummies(test, columns=['Dependents'], drop_first= True)
test = pd.get_dummies(test, columns=['Property_Area'], drop_first= True)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
test[['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']] = ss.fit_transform(test[['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']])
test.head()

test_model = ['Y' if model ==1 else 'N' for model in test_model]

test['Loan_Status'] = test_model[:len(test)]

ID = test['Loan_ID']

test_result = pd.DataFrame({'Loan_ID': ID, 'Loan_Status':test_model[:len(test)]})

test_result.head()

test_result.to_csv('submission.csv')

